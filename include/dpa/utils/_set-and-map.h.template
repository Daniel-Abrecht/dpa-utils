#include <dpa/utils/common.h>
#include <dpa/utils/math.h>
#include <dpa/utils/_math.h>
#include <stdbool.h>

typedef struct DPA__U_SM_PREFIX DPA__U_SM_TYPE;
typedef struct DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _safe) DPA__U_SM_TYPE_IT_S;
typedef struct DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _fast) DPA__U_SM_TYPE_IT_F;

#if defined(DPA__U_SM_MICRO_SET) && DPA__U_SM_KIND == DPA__U_SM_KIND_SET
// For CHAR_BIT == 8, for a set containing one of 256 entries, we only need 256 bits.
// That'd be 32 bytes/chars (because 8 bits per char). For larger integer types, we need less entries.
// u8: 32 entries, u16: 16 entries, u32: 8 entries, u64: 4 entries, u128: 2 entries, u256: 1 entry
// This will not safe any space, but it may make the lookup more efficient. And 32 bytes, is not a lot.
// We round up the number of entres, in case of CHAR_BIT != 8. In that case, space will be wasted, but who's ever going to use such a platform anyway?
struct DPA__U_SM_PREFIX {
  dpa_u_bitmap_entry_t bitmask[(((size_t)1<<(sizeof(DPA__U_SM_KEY_TYPE)*CHAR_BIT))+(sizeof(dpa_u_bitmap_entry_t)*CHAR_BIT-1))/(sizeof(dpa_u_bitmap_entry_t)*CHAR_BIT)];
};
#else
struct DPA__U_SM_PREFIX {
  unsigned char mode; // enum dpa__u_sm_mode. Used to directly select the correct method (empty, list, bitmap)
  unsigned char lbsize; // This is the log 2 of the number of buckets available.
  // After a certain number of entries, it's more efficient to just save the bitmask.
  // The optimal memory usage for a bitmask of a set in bits is `CHAR_BIT**sizeof(DPA__U_SM_KEY_TYPE)`, but see the comment above for real memory usage.
  // The memory usage of a set which actually stores the keys is at least `sizeof(DPA__U_SM_KEY_TYPE) * count`, but a set with open addressing should
  // have a load facter of around 0.75 (75% of allocated entries used), and the memory usage will be that much higher.
  // This implementation will double the memory used by 2 when the load factor reaches 90%.
  // If this type is a map rather than a set, a value, which has type void*, has to be allocated for each entry too.
  // `bitmask` will be used if the amount of memory wasted is <= 50%.
  // Switching if no memory is wasted would also be possible, but since we already always allocate a power of 2 of memory for the key and value lists, there would be no benefits to that.
  size_t count; // This is the number of entries stored in the set.
  union {
    // The key entry is a reversible hash of the original key. This way, the hash does not need to be recalculated,
    // even without storing the key and it's hash.
    DPA__U_SM_KEY_ENTRY_TYPE*restrict key_list;
    dpa_u_bitmap_entry_t*restrict bitmask;
  };
#if DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
  void**restrict value_list;
#endif
};
#endif



#ifndef DPA__U_SM_BO
dpa__u_api dpa_u_unsequenced dpa__u_really_inline inline
DPA__U_SM_KEY_ENTRY_TYPE DPA__U_SM_HASH(const DPA__U_SM_KEY_TYPE x){
#if defined(__GNUC__) || defined(__llvm__)
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wshift-count-overflow"
#elif defined(_MSC_VER)
#pragma warning( push )
#pragma warning( disable : 4293 )
#endif
  return ((DPA__U_SM_KEY_ENTRY_TYPE)x) * dpa__u_choose_prime(DPA__U_SM_KEY_ENTRY_TYPE);
#if defined(__GNUC__) || defined(__llvm__)
#pragma GCC diagnostic pop
#elif defined(_MSC_VER)
#pragma warning( pop )
#endif
}

dpa__u_api dpa_u_unsequenced dpa__u_really_inline inline
DPA__U_SM_KEY_TYPE DPA__U_SM_UNHASH(DPA__U_SM_KEY_ENTRY_TYPE x){
#if defined(__GNUC__) || defined(__llvm__)
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wshift-count-overflow"
#elif defined(_MSC_VER)
#pragma warning( push )
#pragma warning( disable : 4293 )
#endif
  return (DPA__U_SM_KEY_TYPE)(x * dpa__u_choose_prime_inverse(DPA__U_SM_KEY_ENTRY_TYPE));
#if defined(__GNUC__) || defined(__llvm__)
#pragma GCC diagnostic pop
#elif defined(_MSC_VER)
#pragma warning( pop )
#endif
}
#else
dpa__u_api dpa_u_unsequenced inline
DPA__U_SM_KEY_ENTRY_TYPE DPA__U_SM_HASH(const DPA__U_SM_KEY_TYPE n){
  DPA__U_SM_KEY_ENTRY_TYPE e;
  memcpy(e.hash, n.all.all, sizeof(n));
  for(size_t i=sizeof(e.hash)/sizeof(*e.hash),fh=0; i--; )
#if DPA__U_SM_KIND == DPA__U_SM_KIND_SET
    e.hash[i] = fh ^= dpa__u_set_z_hash_sub(e.hash[i]);
#elif DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
    e.hash[i] = fh ^= dpa__u_map_z_hash_sub(e.hash[i]);
#endif
  return e;
}

dpa__u_api dpa_u_unsequenced inline
DPA__U_SM_KEY_TYPE DPA__U_SM_UNHASH(DPA__U_SM_KEY_ENTRY_TYPE e){
  for(size_t i=sizeof(e.hash)/sizeof(*e.hash),fh=0; i--; ){
    size_t hash = e.hash[i];
#if DPA__U_SM_KIND == DPA__U_SM_KIND_SET
    e.hash[i] = dpa__u_set_z_unhash_sub(hash ^ fh);
#elif DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
    e.hash[i] = dpa__u_map_z_unhash_sub(hash ^ fh);
#endif
    fh = hash;
  }
  DPA__U_SM_KEY_TYPE r;
  memcpy(r.all.all, e.hash, sizeof(r));
  return r;
}
#endif



/**
 * This iterator is resilient to changes to the container, and is even usable on different containers.
 * All containers of the same type order their values in the same way, although that order will appear random-ish.
 * If an entry is inserted, that could happen before or after the current iterator position, which determines if it will
 * be iterated over.
 * Before iterating, it is checked if the current entry resides at the current index. If this is not the case, the entry
 * is looked up to determine it's index, or the index it would have had, and the next entry is determined based on the
 * index.
 * The iterator should be 0 initialized. The zero entry can never occur at index 0.
 */
struct DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _safe) {
  DPA__U_SM_KEY_ENTRY_TYPE entry;
#ifdef DPA__U_SM_NO_BITSET
  size_t index;
#else
  DPA__U_SM_ENTRY_HASH_TYPE index;
#endif
};

/**
 * This iterator is fast & simple, but if a set or map is changed in any way, it will be invalid.
 * Also, the first / last entries may be different from the *_it_safe_t iterator, we don't necessarely start at 0 here.
 */
struct DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _fast) {
  size_t index;
};

/**
 * \returns True if the next entry was found, false otherwise.
 */
dpa__u_api bool DPA_U_CONCAT_E(DPA__U_SM_PREFIX, it_safe_next)(const DPA__U_SM_TYPE* that, DPA__U_SM_TYPE_IT_S* it);

/**
 * \returns True if the previous entry was found, false otherwise.
 */
dpa__u_api bool DPA_U_CONCAT_E(DPA__U_SM_PREFIX, it_safe_prev)(const DPA__U_SM_TYPE* that, DPA__U_SM_TYPE_IT_S* it);

/**
 * \returns The value
 */
dpa__u_api dpa_u_reproducible inline
DPA__U_SM_KEY_TYPE DPA_U_CONCAT_E(DPA__U_SM_PREFIX, it_safe_get)(const DPA__U_SM_TYPE_IT_S*const it){
  return DPA__U_SM_UNHASH(it->entry);
}

/**
 * \returns True if the next entry was found, false otherwise.
 */
dpa__u_api bool DPA_U_CONCAT_E(DPA__U_SM_PREFIX, it_fast_next)(const DPA__U_SM_TYPE* that, DPA__U_SM_TYPE_IT_F* it);

/**
 * \returns True if the previous entry was found, false otherwise.
 */
dpa__u_api bool DPA_U_CONCAT_E(DPA__U_SM_PREFIX, it_fast_prev)(const DPA__U_SM_TYPE* that, DPA__U_SM_TYPE_IT_F* it);

/**
 * \returns The value
 */
dpa__u_api dpa_u_reproducible inline
DPA__U_SM_KEY_TYPE DPA_U_CONCAT_E(DPA__U_SM_PREFIX, it_fast_get)(const DPA__U_SM_TYPE* that, const DPA__U_SM_TYPE_IT_F*const it){
  (void)that;
  const size_t i = it->index-1;
#ifndef DPA__U_SM_NO_BITSET
#if !defined(DPA__U_SM_MICRO_SET) || DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
  if(that->lbsize == sizeof(DPA__U_SM_KEY_TYPE)*CHAR_BIT)
#endif
    return DPA__U_SM_UNHASH(i);
#endif
#if !defined(DPA__U_SM_MICRO_SET) || DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
  return DPA__U_SM_UNHASH(that->key_list[i]);
#endif
}

#if DPA__U_SM_KIND == DPA__U_SM_KIND_SET
dpa__u_api int DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_add_first)(DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key);
dpa__u_api int DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_add)(DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key);
dpa__u_api int DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _bitmap_add)(DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key);
/**
 * Adds an entry to the set.
 * \returns 1 if the entry was already present, 0 if not, -1 on error.
 */
dpa__u_api inline
int DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _add)(DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key){
#elif DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
dpa__u_api int DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_set_first)(DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key, void*restrict value);
dpa__u_api int DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_set)(DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key, void*restrict value);
dpa__u_api int DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _bitmap_set)(DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key, void*restrict value);
/**
 * Sets an entry in the map.
 * \returns 1 if an existing entry was overwritten, 0 if not, -1 on error.
 */
dpa__u_api inline int DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _set)(DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key, void*restrict value){
#endif
#if !defined(DPA__U_SM_MICRO_SET) || DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
  switch(that->mode){
    case DPA__U_SM_EMPTY:
#if DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
      return DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_set_first)(that, key, value);
#elif DPA__U_SM_KIND == DPA__U_SM_KIND_SET
      return DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_add_first)(that, key);
#endif
    case DPA__U_SM_LIST:
#ifdef DPA__U_SM_NO_BITSET
    case DPA__U_SM_FINAL:
#endif
#if DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
      return DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_set)(that, key, value);
#elif DPA__U_SM_KIND == DPA__U_SM_KIND_SET
      return DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_add)(that, key);
#endif
#ifndef DPA__U_SM_NO_BITSET
    case DPA__U_SM_BITMAP:
#if DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
      return DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _bitmap_set)(that, key, value);
#elif DPA__U_SM_KIND == DPA__U_SM_KIND_SET
      return DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _bitmap_add)(that, key);
#endif
#endif
  }
  dpa_u_unreachable("set/map: %s"," invalid state");
#else
#if DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
  that->value_list[key] = value;
#endif
  dpa_u_bitmap_entry_t*restrict const b = &that->bitmask[DPA__U_SM_BITMAP_OFFSET(key)];
  const dpa_u_bitmap_entry_t m = DPA__U_SM_BITMAP_BIT(key);
  const bool r = *b & m;
  *b |= m;
  return r;
#endif
}

#if DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
dpa__u_api int DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_exchange)(DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key, void*restrict* value);
dpa__u_api int DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _bitmap_exchange)(DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key, void*restrict* value);
/**
 * Sets an entry in the map and returns the existing one if one exists.
 * If there was none, the variable will remain unchanged.
 * \returns 1 if an existing entry was overwritten, 0 if not, -1 on error.
 */
dpa__u_api inline
int DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _exchange)(DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key, void*restrict*const value){
#if !defined(DPA__U_SM_MICRO_SET) || DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
  switch(that->mode){
    case DPA__U_SM_EMPTY:
      return DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_set_first)(that, key, *value);
    case DPA__U_SM_LIST:
#ifdef DPA__U_SM_NO_BITSET
    case DPA__U_SM_FINAL:
#endif
      return DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_exchange)(that, key, value);
#ifndef DPA__U_SM_NO_BITSET
    case DPA__U_SM_BITMAP:
      return DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _bitmap_exchange)(that, key, value);
#endif
  }
  dpa_u_unreachable("set/map: %s"," invalid state");
#else
  dpa_u_bitmap_entry_t*restrict const b = &that->bitmask[DPA__U_SM_BITMAP_OFFSET(key)];
  const dpa_u_bitmap_entry_t m = DPA__U_SM_BITMAP_BIT(key);
  const bool r = *b & m;
  *b |= m;
  void*const v = *value;
  if(r) *value = that->value_list[key];
  that->value_list[key] = v;
  return r;
#endif
}
#endif

/**
 * Removes an entry.
 * \returns true if the entry was present, false otherwise.
 */
dpa__u_api bool DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _remove)(DPA__U_SM_TYPE* that, DPA__U_SM_KEY_TYPE key);

/**
 * Checks if an entry is present.
 * \returns true if the entry was present, false otherwise.
 */
#ifdef DPA__U_SM_NO_BITSET
dpa_u_reproducible dpa__u_api bool DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _has)(const DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key);
#else
dpa_u_reproducible dpa__u_api bool DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_has)(const DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key);
dpa_u_reproducible dpa__u_api inline
bool DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _has)(const DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key){
#if !defined(DPA__U_SM_MICRO_SET) || DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
  switch(that->mode){
    case DPA__U_SM_EMPTY: return false;
    case DPA__U_SM_LIST: return DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_has)(that, key);
    case DPA__U_SM_BITMAP: {
      const DPA__U_SM_ENTRY_HASH_TYPE hash = DPA__U_SM_HASH(key);
      return that->bitmask[DPA__U_SM_BITMAP_OFFSET(hash)] & DPA__U_SM_BITMAP_BIT(hash);
    }
  }
  dpa_u_unreachable("set/map: %s"," invalid state");
#else
  return that->bitmask[DPA__U_SM_BITMAP_OFFSET(key)] & DPA__U_SM_BITMAP_BIT(key);
#endif
}
#endif

/**
 * Removes all entries, frees all allocations
 */
dpa__u_api void DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _clear)(DPA__U_SM_TYPE* that);

#if DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
/**
 * Returns the entry.
 */
#ifdef DPA__U_SM_NO_BITSET
dpa_u_reproducible dpa__u_api dpa_u_optional_pointer_t DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _get)(const DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key);
#else
dpa_u_reproducible dpa__u_api dpa_u_optional_pointer_t DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_get)(const DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key);
dpa_u_reproducible dpa__u_api inline
dpa_u_optional_pointer_t DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _get)(const DPA__U_SM_TYPE*restrict that, DPA__U_SM_KEY_TYPE key){
#if !defined(DPA__U_SM_MICRO_SET) || DPA__U_SM_KIND == DPA__U_SM_KIND_MAP
  switch(that->mode){
    case DPA__U_SM_EMPTY: return (dpa_u_optional_pointer_t){0};
    case DPA__U_SM_LIST: return DPA_U_CONCAT_E(DPA___U_SM_PREFIX, _list_get)(that, key);
    case DPA__U_SM_BITMAP: {
      const DPA__U_SM_ENTRY_HASH_TYPE hash = DPA__U_SM_HASH(key);
      if(!(that->bitmask[DPA__U_SM_BITMAP_OFFSET(hash)] & DPA__U_SM_BITMAP_BIT(hash)))
        return (dpa_u_optional_pointer_t){0};
      return (dpa_u_optional_pointer_t){
        .value = that->value_list[hash],
        .present = true
      };
    }
  }
  dpa_u_unreachable("set/map: %s"," invalid state");
#else
  if(!that->bitmask[DPA__U_SM_BITMAP_OFFSET(key)] & DPA__U_SM_BITMAP_BIT(key))
    return (dpa_u_optional_pointer_t){0};
  return (dpa_u_optional_pointer_t){
    .value = that->value_list[key],
    .present = true
  };
#endif
}
#endif

/**
 * Removes and returns an entry.
 */
dpa__u_api dpa_u_optional_pointer_t DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _get_and_remove)(DPA__U_SM_TYPE* that, DPA__U_SM_KEY_TYPE key);
#endif

#if defined(DPA__U_SM_MICRO_SET) && DPA__U_SM_KIND == DPA__U_SM_KIND_SET
dpa_u_reproducible dpa__u_api inline
size_t DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _count)(const DPA__U_SM_TYPE* that){
  size_t n = 0;
  const dpa_u_bitmap_entry_t*restrict const bitmask = that->bitmask;
  for(unsigned i=0; i<(((size_t)1<<(sizeof(DPA__U_SM_KEY_TYPE)*CHAR_BIT))+(sizeof(dpa_u_bitmap_entry_t)*CHAR_BIT-1))/(sizeof(dpa_u_bitmap_entry_t)*CHAR_BIT); i++)
    n += dpa_u_count_bits(bitmask[i]);
  return n;
}
#else
dpa_u_reproducible dpa__u_really_inline dpa__u_api inline
size_t DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _count)(const DPA__U_SM_TYPE* that){
  return that->count;
}
#endif

/**
 * For debugging purposes only
 */
dpa__u_api void DPA_U_CONCAT_E(DPA__U_SM_PREFIX, _dump_hashmap_key_hashes)(DPA__U_SM_TYPE* that);

//////////////////////////////////////////////
